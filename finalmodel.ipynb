{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\psara\\\\Desktop\\\\SARANYA_VS\\\\guvifinal\\\\sales_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Dept</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekly_Sales_log</th>\n",
       "      <th>Temperature_log</th>\n",
       "      <th>MarkDown_Total_log</th>\n",
       "      <th>Unemployment_log</th>\n",
       "      <th>Expected_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.123647</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.123647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.831831</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.831831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>9.528148</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>9.528148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.595510</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.595510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.380665</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.380665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.819556</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>16.385208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.557242</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>17.122894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>10.933437</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>19.499089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.827392</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>17.393044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.982677</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>15.548329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Type    Size  Dept  IsHoliday  Fuel_Price         CPI  Day  \\\n",
       "0           1     1  151315     1          0       2.572  211.096358    5   \n",
       "1           1     1  151315     2          0       2.572  211.096358    5   \n",
       "2           1     1  151315     3          0       2.572  211.096358    5   \n",
       "3           1     1  151315     4          0       2.572  211.096358    5   \n",
       "4           1     1  151315     5          0       2.572  211.096358    5   \n",
       "...       ...   ...     ...   ...        ...         ...         ...  ...   \n",
       "421565     45     2  118221    93          0       3.882  192.308899   26   \n",
       "421566     45     2  118221    94          0       3.882  192.308899   26   \n",
       "421567     45     2  118221    95          0       3.882  192.308899   26   \n",
       "421568     45     2  118221    97          0       3.882  192.308899   26   \n",
       "421569     45     2  118221    98          0       3.882  192.308899   26   \n",
       "\n",
       "        Month  Year  Weekly_Sales_log  Temperature_log  MarkDown_Total_log  \\\n",
       "0           2  2010         10.123647         3.768384            0.000000   \n",
       "1           2  2010         10.831831         3.768384            0.000000   \n",
       "2           2  2010          9.528148         3.768384            0.000000   \n",
       "3           2  2010         10.595510         3.768384            0.000000   \n",
       "4           2  2010         10.380665         3.768384            0.000000   \n",
       "...       ...   ...               ...              ...                 ...   \n",
       "421565     10  2012          7.819556         4.091841            8.565652   \n",
       "421566     10  2012          8.557242         4.091841            8.565652   \n",
       "421567     10  2012         10.933437         4.091841            8.565652   \n",
       "421568     10  2012          8.827392         4.091841            8.565652   \n",
       "421569     10  2012          6.982677         4.091841            8.565652   \n",
       "\n",
       "        Unemployment_log  Expected_Sales  \n",
       "0               2.208934       10.123647  \n",
       "1               2.208934       10.831831  \n",
       "2               2.208934        9.528148  \n",
       "3               2.208934       10.595510  \n",
       "4               2.208934       10.380665  \n",
       "...                  ...             ...  \n",
       "421565          2.268718       16.385208  \n",
       "421566          2.268718       17.122894  \n",
       "421567          2.268718       19.499089  \n",
       "421568          2.268718       17.393044  \n",
       "421569          2.268718       15.548329  \n",
       "\n",
       "[421570 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'Type', 'Size', 'Dept', 'IsHoliday', 'Fuel_Price', 'CPI',\n",
       "       'Day', 'Month', 'Year', 'Weekly_Sales_log', 'Temperature_log',\n",
       "       'MarkDown_Total_log', 'Unemployment_log', 'Expected_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeRegressor\n",
      "Mean Absolute Error: 0.0062\n",
      "Mean Squared Error: 0.0003\n",
      "Root Mean Squared Error: 0.0173\n",
      "R^2 Score: 0.9999\n",
      "----------------------------------------\n",
      "Model: ExtraTreesRegressor\n",
      "Mean Absolute Error: 0.0062\n",
      "Mean Squared Error: 0.0002\n",
      "Root Mean Squared Error: 0.0146\n",
      "R^2 Score: 0.9999\n",
      "----------------------------------------\n",
      "Model: RandomForestRegressor\n",
      "Mean Absolute Error: 0.0021\n",
      "Mean Squared Error: 0.0001\n",
      "Root Mean Squared Error: 0.0075\n",
      "R^2 Score: 1.0000\n",
      "----------------------------------------\n",
      "Model: AdaBoostRegressor\n",
      "Mean Absolute Error: 0.4919\n",
      "Mean Squared Error: 0.3607\n",
      "Root Mean Squared Error: 0.6006\n",
      "R^2 Score: 0.8948\n",
      "----------------------------------------\n",
      "Model: GradientBoostingRegressor\n",
      "Mean Absolute Error: 0.0631\n",
      "Mean Squared Error: 0.0115\n",
      "Root Mean Squared Error: 0.1072\n",
      "R^2 Score: 0.9967\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def machine_learning(df, algorithm):\n",
    "    # Specify features (X) and target variable (y)\n",
    "    X = df.drop('Weekly_Sales_log', axis=1)\n",
    "    y = df['Weekly_Sales_log']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # Train and evaluate the selected algorithm\n",
    "    model = algorithm\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    " # Store results in the dictionary\n",
    "    results['MAE'] = mae\n",
    "    results['MSE'] = mse\n",
    "    results['RMSE'] = rmse\n",
    "    results['R2'] = r2\n",
    "\n",
    "    return results\n",
    "\n",
    "# List of algorithms\n",
    "algorithms = [\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    ExtraTreesRegressor(random_state=42),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    AdaBoostRegressor(random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42)\n",
    "]\n",
    "# Iterate through algorithms and print results\n",
    "for algorithm in algorithms:\n",
    "    results = machine_learning(df, algorithm)\n",
    "    print(f'Model: {algorithm.__class__.__name__}')\n",
    "    print(f'Mean Absolute Error: {results[\"MAE\"]:.4f}')\n",
    "    print(f'Mean Squared Error: {results[\"MSE\"]:.4f}')\n",
    "    print(f'Root Mean Squared Error: {results[\"RMSE\"]:.4f}')\n",
    "    print(f'R^2 Score: {results[\"R2\"]:.4f}')\n",
    "    print('-' * 40)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance of regression algorithms using standard metrics such as\n",
    "# Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R2) score.\n",
    "# It takes time to train and evaluate the selected algorithm around 10-15 minutes.please wait till it completes.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTreesRegressor and RandomForestRegressor perform the best among the models,\n",
    "# with lower MAE, MSE, and RMSE, indicating better prediction accuracy and precision.\n",
    "# They also have higher R2 scores, suggesting a better fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: hyper parameter tuning is a process of selecting best parameters from set of parameters values  to increase the model performace\n",
    "# Grid search cv is the one of the method for hyper parameter tuning\n",
    "# it takes time around 2 hours to select the best parameters, please wait till it completes.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 4, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [5, 10, 15]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 4, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [5, 10, 15]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, 15],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [2, 4, 6],\n",
       "                         'min_samples_split': [5, 10, 15]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the feature matrix (X) and target vector (y)\n",
    "x = df.drop(['Weekly_Sales_log'], axis=1)\n",
    "y = df['Weekly_Sales_log']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a reduced parameter grid\n",
    "param_grid_r = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [5, 10, 15],\n",
    "    'min_samples_leaf': [2, 4, 6],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_r = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "                             param_grid=param_grid_r,\n",
    "                             cv=5,\n",
    "                             n_jobs=-1)\n",
    "# Fit GridSearchCV to training data\n",
    "grid_search_r.fit(x_train, y_train)\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Best Score: 0.9740345173302579\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search_r.best_params_\n",
    "\n",
    "score = grid_search_r.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "print(\"Best Score:\", score)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9763494960654855, 0.973273697066997)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the parameters and check the accuracy for both training and testing & overfitting\n",
    "\n",
    "x = df.drop(columns=['Weekly_Sales_log'], axis=1)\n",
    "y = df['Weekly_Sales_log']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(max_depth=15, max_features='log2', min_samples_leaf=4, min_samples_split=10).fit(x_train, y_train)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "r2_train, r2_test\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R2': 0.9749387676579241,\n",
       " 'Mean Absolute Error': 0.19821253951204326,\n",
       " 'Mean Squared Error': 0.08595683670039449,\n",
       " 'Root Mean Squared Error': 0.29318396392093904}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the sales with hypertuning parameters and calculate the accuracy using metrics\n",
    "\n",
    "x = df.drop(columns=['Weekly_Sales_log'], axis=1)\n",
    "y = df['Weekly_Sales_log']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(max_depth=15, max_features='log2', min_samples_leaf=4, min_samples_split=10).fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "metrics_r = {'R2': r2,\n",
    "           'Mean Absolute Error': mae,\n",
    "           'Mean Squared Error': mse,\n",
    "           'Root Mean Squared Error': rmse}\n",
    "\n",
    "metrics_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Dept</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekly_Sales_log</th>\n",
       "      <th>Temperature_log</th>\n",
       "      <th>MarkDown_Total_log</th>\n",
       "      <th>Unemployment_log</th>\n",
       "      <th>Expected_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.123647</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.123647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.831831</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.831831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>9.528148</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>9.528148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.595510</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.595510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.380665</td>\n",
       "      <td>3.768384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.208934</td>\n",
       "      <td>10.380665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.819556</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>16.385208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.557242</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>17.122894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>10.933437</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>19.499089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.827392</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>17.393044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.982677</td>\n",
       "      <td>4.091841</td>\n",
       "      <td>8.565652</td>\n",
       "      <td>2.268718</td>\n",
       "      <td>15.548329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Type    Size  Dept  IsHoliday  Fuel_Price         CPI  Day  \\\n",
       "0           1     1  151315     1          0       2.572  211.096358    5   \n",
       "1           1     1  151315     2          0       2.572  211.096358    5   \n",
       "2           1     1  151315     3          0       2.572  211.096358    5   \n",
       "3           1     1  151315     4          0       2.572  211.096358    5   \n",
       "4           1     1  151315     5          0       2.572  211.096358    5   \n",
       "...       ...   ...     ...   ...        ...         ...         ...  ...   \n",
       "421565     45     2  118221    93          0       3.882  192.308899   26   \n",
       "421566     45     2  118221    94          0       3.882  192.308899   26   \n",
       "421567     45     2  118221    95          0       3.882  192.308899   26   \n",
       "421568     45     2  118221    97          0       3.882  192.308899   26   \n",
       "421569     45     2  118221    98          0       3.882  192.308899   26   \n",
       "\n",
       "        Month  Year  Weekly_Sales_log  Temperature_log  MarkDown_Total_log  \\\n",
       "0           2  2010         10.123647         3.768384            0.000000   \n",
       "1           2  2010         10.831831         3.768384            0.000000   \n",
       "2           2  2010          9.528148         3.768384            0.000000   \n",
       "3           2  2010         10.595510         3.768384            0.000000   \n",
       "4           2  2010         10.380665         3.768384            0.000000   \n",
       "...       ...   ...               ...              ...                 ...   \n",
       "421565     10  2012          7.819556         4.091841            8.565652   \n",
       "421566     10  2012          8.557242         4.091841            8.565652   \n",
       "421567     10  2012         10.933437         4.091841            8.565652   \n",
       "421568     10  2012          8.827392         4.091841            8.565652   \n",
       "421569     10  2012          6.982677         4.091841            8.565652   \n",
       "\n",
       "        Unemployment_log  Expected_Sales  \n",
       "0               2.208934       10.123647  \n",
       "1               2.208934       10.831831  \n",
       "2               2.208934        9.528148  \n",
       "3               2.208934       10.595510  \n",
       "4               2.208934       10.380665  \n",
       "...                  ...             ...  \n",
       "421565          2.268718       16.385208  \n",
       "421566          2.268718       17.122894  \n",
       "421567          2.268718       19.499089  \n",
       "421568          2.268718       17.393044  \n",
       "421569          2.268718       15.548329  \n",
       "\n",
       "[421570 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.039357958935085"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually pass the user input and predict the department wide sales for each store in the following year.\n",
    "user_data = np.array([[1,2,118221,93,0,3.882,211.096358,5,2,2010,3.768384,0.000000,2.208934,10.595510]])\n",
    "y_pred = model.predict(user_data)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Department-Wide Sales: 10.039357958935085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have feature names in a list (replace with your actual feature names)\n",
    "feature_names = ['Store', 'Type', 'Size', 'Dept', 'IsHoliday', 'Fuel_Price', 'CPI', 'Day', 'Month', 'Year', 'Temperature_log', 'MarkDown_Total_log', 'Unemployment_log','Expected_Sales']\n",
    "\n",
    "# Manually pass user input features with feature names\n",
    "user_data = pd.DataFrame([[1, 2, 118221, 93, 0, 3.882, 211.096358, 5, 2, 2010, 3.768384, 0.000000, 2.208934, 10.595510]], columns=feature_names)\n",
    "\n",
    "# Predict department-wide sales\n",
    "y_pred = model.predict(user_data)\n",
    "\n",
    "# Print or use the predicted sales\n",
    "print(\"Predicted Department-Wide Sales:\", y_pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22910.66860345567"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Inverse Log Transformation to convert the value to original scale of the data (exp)\n",
    "np.exp(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the regression model by using pickle\n",
    "import pickle\n",
    "with open('reg_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Department-Wide Sales: 22910.66860345567\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle model\n",
    "with open('C:\\\\Users\\\\psara\\\\Desktop\\\\SARANYA_VS\\\\guvifinal\\\\reg_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Your input data (replace this with your actual input data)\n",
    "user_data = np.array([[1, 2, 118221, 93, 0, 3.882, 211.096358, 5, 2, 2010, 3.768384, 0.000000, 2.208934, 10.595510]])\n",
    "\n",
    "# Feature names for your input data (replace this with actual feature names)\n",
    "feature_names = ['Store', 'Type', 'Size', 'Dept', 'IsHoliday', 'Fuel_Price', 'CPI', 'Day', 'Month', 'Year', 'Temperature_log', 'MarkDown_Total_log', 'Unemployment_log','Expected_Sales']\n",
    "\n",
    "# Create a DataFrame with the input data and feature names\n",
    "user_df = pd.DataFrame(user_data, columns=feature_names)\n",
    "\n",
    "# Make predictions by providing the input data (X) to the predict method\n",
    "y_pred = model.predict(user_df)\n",
    "\n",
    "# Assuming you're using log-transformed target values, exponentiate the prediction\n",
    "predicted_price = np.exp(y_pred[0])\n",
    "\n",
    "# Print the predicted selling price\n",
    "print(\"Predicted Department-Wide Sales:\", predicted_price)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
